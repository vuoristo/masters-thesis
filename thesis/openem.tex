\chapter{Open Event Machine}
\label{chapter:openem}
This thesis investigates the suitability of Open Event Machine (OpenEM) for
real-time stream processing. OpenEM is a programming framework for event-driven
multicore applications.

\section{OpenEM Framework}
\subsection{Overview}
OpenEM is an event-driven programming framework originally developed for the
networking data plane by Nokia Solutions and Networks. The OpenEM framework
provides a programming model for scalable and dynamically load balanced
applications. The key components of the OpenEM programming model are events,
execution objects, queues and the scheduler. OpenEM works with
run-to-completion principle which means once an event begins to execute it will
not be interrupted but will run until completed. The run-to-completion
principle implies limitations within which well performing applications must be
designed, the main limitations being the required small granule size for
computations and the lock-free implementation of the application.
\cite{openempage}

At the time of writing there are no public documentation resources for the NSN
OpenEM other than the documentation included in the OpenEM source files
available at \cite{openempage} and the introductory slides at
\cite{openemintro}. Hardware vendor implementations of OpenEM exist and may
have more complete documentation available as is the case for the Texas
Instruments OpenEM implementation introduced in section \ref{sec:tiopenem}.

The unit of communication in OpenEM is the Event described in
\ref{subsec:event}. Events are sent to Queues (\ref{subsec:queues}). Queues are
connected to Execution Objects (\ref{subsec:eos}). The scheduler
(\ref{subsec:schedule}) chooses an event from a suitable queue based on
scheduling rules and schedules it on a core.

\subsection{Events}
\label{subsec:event}
In the core of the OpenEM framework design is the event. The work to be done by
an OpenEM application is divided into application specific pieces of data
called events. OpenEM does not specify the event content to allow for the use
of hardware specific descriptors in OpenEM implementations for different
hardware platforms. Usually events carry pointers to messages or descriptors.
\cite{openemintro} For example in a network packet processing application an
arriving packet could be converted to or encapsulated by an event.

Event memory is managed by OpenEM, meaning the application allocates events
from OpenEM and freeing events returns the control of the memory to OpenEM
\cite{openemintro}.
\subsection{Execution Objects}
\label{subsec:eos}
The work to be done is described by the events but they don't describe how it
is done. For that purpose there are \textbf{Execution Objects} (EO), which
contain the application logic. The application is built from EOs connected by
queues.  Multiple queues can be connected to an EO and an EO may execute on
multiple cores if the queue types of the connected queues allow for it.
\cite{openemintro}

The application logic for each EO is contained in three functions, namely
start, receive and stop, which will get called in different phases of the EO
lifecycle. EO construction and destruction are handled through the application
defined start and stop functions. The receive function will be called whenever
the EO has received an event and is scheduled on a core. \cite{openemintro}

OpenEM implementations will pass a pointer to an user defined context when
calling the receive function. The application designer has complete freedom
over the EO context contents as the OpenEM runtime only passes an user defined
pointer. \cite{openemintro} The application designer should note that as
locking is discouraged and the EO may execute on multiple cores simultaneously,
care must be exercised when accessing the EO context.

\subsection{Queues}
\label{subsec:queues}
The queues attached to the EOs define how the EOs are executed. A queue is
always attached to a single EO but an EO can have multiple queues attached.
Events are sent to queues and scheduled for execution based on queue scheduling
properties: priority, type and queue group. \cite{openemintro}

There are for types of queues: atomic, parallel, parallel ordered and
unscheduled \cite{openemintro}. The programming construct representing the
queues is the same type for all queues but here a queue which type is atomic
will be called an atomic queue for simplicity, this applies to other queues as
well. Events are sent to all queue types the same way using the send function,
the different queue types only affect the scheduling of the events
\cite{openemintro}.

Only one event from an \textbf{atomic queue} may be scheduled at a time. As the
use of locks is discouraged, atomic queues can be used when the application
needs to write shared memory locations. Events from \textbf{parallel queues} can
be scheduled on any core at any time according to other scheduling rules
explained in section \ref{subsec:schedule}. Events received from a
\textbf{parallel ordered queue} are scheduled like events from parallel queues
but OpenEM will restore the event ordering before events are forwarded to other
queues even if the processing of the events ends out of order. The
\textbf{unscheduled queues} are special in that they are not scheduled
automatically. The events are sent to unscheduled queues in the same way they
are sent to the other queue types, but they need to be explicitly dequeued from
the unscheduled queues. Unscheduled queues cannot be added to EOs.
\cite{openempage}

Queues belong to \textbf{queue groups}. Queue groups define the set of cores
the events from the queues in the queue group can be scheduled on. Queue groups
can be used for example to separate application layers, control load balancing
or help guarantee that quality of service or latency targets are reached.
\cite{openemintro} Queue groups can be modified at initialization of the queues
or later during the execution \cite{openempage}. Possibility for modifying the
queue groups during execution can help in load balancing the application
dynamically.

\subsection{Scheduling}
\label{subsec:schedule}
OpenEM does not define queue scheduling disciplines in detail
\cite{openempage}. The \textbf{scheduler} is implemented in hardware or
software and is specific to the OpenEM implementation. The purpose of the
scheduler across the OpenEM implementations is to dequeue events from the
queues according to its scheduling rules. \cite{openemintro} Queue types and
queue groups affect the scheduling as described in \ref{subsec:queues}.

Each core executes the dispatcher which will be called by the scheduler
whenever an event is scheduled on the core. The dispatcher can run either in an
OS thread or on bare metal. Dispatcher checks which queue the event was
dequeued from and calls the receive function of the EO associated with that
queue. \cite{openemintro}

\subsection{An Illustrative Example}
\label{subsec:example}
Present a graphical representation of a simple OpenEM application\\
Explain the execution of the application

\section{Texas Instruments Implementation of OpenEM}
\label{sec:tiopenem}
\subsection{Multicore Navigator and OpenEM}
Centralized Scheduler on a PDSP core\\
Hardware queues\\
\subsection{Other TI Specific OpenEM features}
Scheduling\\
Tracing\\
Event Preloading??\\
Initialization of OpenEM\\
Cache Coherency
\subsection{State of TI OpenEM Implementation}
Event Groups\\
Distributed Scheduling\\
Queue Group limitations\\
Execution Object context\\
Parallel Ordered Queue\\


