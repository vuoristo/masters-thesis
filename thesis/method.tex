\chapter{Performance Analysis of Software Systems}
\label{chapter:perfanalysis}
\section{Performance Analysis}
In this chapter the measurement and performance comparison of software systems
is explained.

The performance analysis of software systems can be split in to three
categories, which are analytical modeling, simulation and measurements. Jain
\cite{jain1991art} defines analytical modeling as using mathematical models to
abstract the key features of the system under study and using these models to
make predictions of the system. Models used in simulations are based on
mathematical abstractions as well. The key difference between analytical
modeling and simulation is the notion of time used in simulation. Analytical
modeling solves the system state at a fixed point in time, in contrast to
simulators where the system state is computed iteratively at multiple points in
time. Analytical modeling and simulation can be used for explorative study of
systems that do not yet exist, whereas analysis using measurements can not be
performed unless the real world system under study exists. The data the
measurements yield is used as the starting point for analysis of the system
under study. \cite{jain1991art}

The successful comparison of software systems requires meaningful and reasonably
accurate measurements of both of the systems. The measurements are obtained by
monitoring the system while it is being subjected to a particular workload
\cite{jain1991art}. Often the monitored applications are built for the
comparison purpose only and therefore any workload they are subjected to is an
approximation of the real world workload that would be processed by their real
world application counterparts. These approximate workloads are called synthetic
workloads \cite{jain1991art}. The use of synthetic workload gives more control
over the test conditions and most importantly makes the experiments repeatable.
Workload selection requires care because the synthetic workload needs to mimic
its real world counterpart with high accuracy. Performance analysis is often
conducted to understand the performance or feasibility of a software component
or system that does not exist yet. If the real world version of the workload
does not exist or is not available for study the selection of a workload that
loads the system in a realistic way is difficult \cite{jain1991art}.

\subsection{Measuring Software Systems}
\label{subsec:measure}
This thesis studies the OpenEM application through measurements. In this
subsection a closer look at measuring software systems is provided.

Parameters, factors

The software measurement tools are called monitors which can be implemented both
in hardware and in software. Monitors are classified to software monitors,
hardware monitors, firmware monitors or hybrid monitors depending on the
implementation level of the monitor. The implementation level of the monitor
affects the level of events that are convenient to measure with it. For example
hardware monitors can monitor the state of registers and hardware counters but
have difficulties in observing the status of software constructs such as the
execution of functions. The software monitors on the other hand can be used to
monitor the status of software components but gathering information about the
status of the hardware is more difficult and in some cases impossible.
\cite{jain1991art} For example it is very complicated to determine whether a
memory operation hit a given level of cache or not using software alone but many
hardware platforms offer hardware counters to monitor the cache hits and misses.

\subsection{Analysis of results}

\fixme{needs to have an overview of performance analysis and better explain the
common steps of all methods.}
\fixme{maybe check other sources as well? how about the stuff saarinen uses?
there are also more refs in hanhirova thesis}

