\chapter{Data Streams}
\label{chapter:streams}
The amount of digital data that is being created and copied is increasing at a massive pace. EMC Digital Universe study \cite{turner2014digital} estimates that the data we create and copy annually was 4.4 zettabytes in 2013 and is going to reach 44 zettabytes by 2020. A large portion of this data growth is due to increased volume of entertainment in the form of audio and video being streamed through the Internet. New data sources such as embedded sensors are contributing to the explosive data growth as well. Most of the data being created or copied is transient and thus does not require long term storage.~\cite{turner2014digital}

Distributed data processing systems such as Hadoop~\cite{white2012hadoop} were developed for batch processing of Big Data. The batch processing systems are capable of processing massive amounts of data but the processing has high latency. As most of the growth in data creation and copying is coming from data that is not stored, batch processing is not the optimal processing method for data.

Consider live streaming of video as an example of modern application with specific data processing needs. A camera filming a live scene is generating the data and the users expect to access the video stream over the Internet with low latency. Many distinct processing steps are required in order to get the video frames from the camera to the viewer, all of which need to be performed in few milliseconds on the frames flowing past the processing units. In addition to video streams, many other kinds of data streams, which have similar processing needs are produced at an accelerating pace. Certain technologies developed for processing the streaming data are grouped under the term stream processing.

An introduction to stream processing and selected stream processing techniques are given in this chapter. A stream processing overview is given in \ref{sec:stream-processing}. Selected streaming applications and their common features are described in \ref{subsec:streaming-applications}. Platforms used for stream processing are introduced in~\ref{subsec:stream-processing-platforms}. Video streams are discussed as an example of a common type of streaming data in \ref{subsec:video-streams}. Dataflow Models of Computation are discussed in \ref{subsec:dataflow-moc} as an example of solution for stream processing. Variations of dataflow MoC are examined, synchronous dataflow in \ref{subsec:synchronous-dataflow} and dynamic dataflow in \ref{subsec:dynamic-dataflow}.

\section{Stream Processing}
\label{sec:stream-processing}
Stream processing is a method of computing over streaming data. Stream processing is often used to refer to the programming paradigm that follows the stream processing method but stream processing is not limited to the creation of software. Stream processing term has been used in the literature to describe different kinds of methods that deal with streaming data. In the context of this thesis, the broad definition of stream processing as a method of processing any kind of streaming data is used.

Stream processing paradigm defines modules that compute in parallel and communicate data via channels. The modules can be divided into three classes according to their placement and purpose in the process. The classes are sources, filters, and sinks. Sources act as the input points that pass data into the process. Filters perform atomic computations on the streams. Sinks are used to pass the data out from the process.~\cite{stephens1997survey}

In stream processing, the channels of communication between the modules are called streams. Streams can be described as infinite lists of elements taken from a dataset $A$. Mathematical formalization of a stream is a function $f:T \rightarrow A$ where $T = \mathbb{N}$ represents discrete time.~\cite{stephens1997survey} For example, the input stream of a signal processing application can be the sample based input sequence, which has been generated by sampling a sensor at fixed time intervals.

Systems built following the stream processing method can be categorized under stream processing systems. The stream processing survey by Stephens \cite{stephens1997survey} categorizes \textit{dataflow systems}, \textit{reactive systems}, \textit{synchronous concurrent algorithms}, \textit{signal processing systems}, and some \textit{real-time systems} as stream processing systems.

\subsection{Applications of Stream Processing}
\label{subsec:streaming-applications}
The authors of the StreamIt language~\cite{thies2002streamit} have defined \textit{streaming applications} as a class of programs, which commonly have many of the features defined in the following listing.

\begin{itemize}
    \item \textit{Large streams of data.} A streaming application operates on large, virtually infinite streams of data.
    \item \textit{Independent stream filters.} The filters of a streaming application are generally self-contained. They perform atomic operations on the stream.
    \item \textit{A stable computation pattern.} A streaming application has a steady state of operation during which the graph formed by the filters remains mostly constant.
    \item \textit{Occasional modification of the stream structure.} A streaming application can occasionally modify the processing graph as a reaction to changed input or some other condition.
    \item \textit{Occasional out-of-stream communication.} The high volume communication between the filters is handled through the streams but the filters may communicate small amount of control data outside the stream.
    \item \textit{High performance expectations.} There often are real-time and power consumption constraints on streaming applications. For example, a streaming video decoder has to decode the stream at rate of input in order to avoid unbounded buffer growth and frame dropping.
\end{itemize}

Applications that handle streams of audio and video often have the above features and can be implemented following the stream processing paradigm. The multimedia domain is therefore full of examples of stream processing applications. Video conferencing is a commonly used example of a streaming application, streaming video decoding is used in online video streaming services, and audio streams are encoded and decoded in mobile devices for calls and also in streaming of music.

In addition to multimedia, streaming data is often encountered in other kinds of internet services as well. For example, efficient computation of analytics from search engine data can be implemented following stream processing paradigm. The total dataset may be quite large and a batch computing system computing over the complete data would provide results with high latency. A stream processing system, on the other hand, would be able to compute the analytics from the data as the data is being produced and update the analytics separately for each piece of data received. Google has developed the MillWheel framework for implementation of such analytics~\cite{tyler2013millwheel}.

\subsection{Stream Processing Platforms}
\label{subsec:stream-processing-platforms}
A diverse variety of stream processing applications may run on different platforms ranging from phones to servers. Software stream processing systems may execute on arbitrary hardware, but to achieve good performance some platforms are preferred over the others. Stream processing is well suited for designing applications for GPUs and DSPs. The modules of stream processing can often be executed in parallel allowing for efficient use of the multiple cores of GPUs, for example~\cite{goddeke2011fast}, makes use of GPUs for solving simulations involving partial differential equations using GPUs.

Digital signal processing applications are often designed in stream processing pattern and this is also reflected in the hardware making DSPs potentially powerful stream processing units~\cite{lee2015introduction}. Multi-core DSPs such as the Texas instruments TMS320C6678 used in this thesis have the potential for efficient stream processing, because they combine the DSP architecture suitable for stream processing with the parallel processing capabilities of the multiple cores.

In the software world, the expression power of stream processing paradigm has been recognized and many tools have been created for the development of stream processing applications. Examples of stream processing frameworks for distributed computing are Google MillWheel~\cite{tyler2013millwheel}, Apache Storm~\cite{apache2016storm}, and Apache Spark Streaming~\cite{apache2016spark}. StreamIT introduced in~\cite{thies2002streamit} is a programming language specifically for stream processing. Streaming Concurrent Collections~\cite{sbirlea2011scnc} is a stream processing system based on the Concurrent Collections~\cite{budimlic2010concurrent} programming model.

In addition to the software stream processing systems studied in this thesis, the increasing volume of streaming data has motivated research for hardware stream processors. Processor architectures that implement stream processing concepts in the hardware have been researched in Imagine \cite{kapasi2002imagine} and Merrimac~\cite{dally2003merrimac} projects at Stanford University.

\subsection{Video Streams}
\label{subsec:video-streams}
Video streams are a prime example of streaming data. In the case of streaming service such as Netflix, the video data is downloaded from the server of the service provider and decompressed on the device of the consumer. In most use cases, the video streams are decompressed as they are downloaded and the complete video file is not necessarily stored on the device. Thus, stream processing is well suited for video stream decompression. The video streams are often accompanied by audio streams, which are processed similarly.~\cite{richardson2002video}

The video conference use case is similar to the streaming video services but involves extra complexity with the compression of the raw data coming from the video camera and especially the requirement of low latency in the compression, decompression, and communication.

A large fraction of the growth of data creation can be attributed to video streams. More than billion hours of TV and movies are streamed through the video streaming service Netflix \cite{turner2014digital}. Video streams are used for real-time communication through services such as Skype and Periscope. In addition to the number of users accessing the streams growing the bit rate of the streams is growing as well. The efficiency of video stream processing is thus a top priority in the industry.

\section{Dataflow}
\label{sec:dataflow-models}
Stream processing defines the high-level structure of how streaming data is to be processed but it does not define the stream processing methods in detail. On a high-level, the structure defined by dataflow models of computation corresponds well to stream processing. Looking at dataflow as the model of computation for stream processing is thus potentially useful. In this section the dataflow models of computation are examined.

\subsection{Dataflow Models of Computation}
\label{subsec:dataflow-moc}
Dataflow models of computation can be used to describe stream processing applications. In programs following a dataflow MoC, the computation can be described by a directed graph. The nodes of the graph are the computation kernels. The data being processed by the application is split into tokens, which flow from node to node along the directed arcs. The only means of communication between the nodes are the data tokens. This means the dependencies of a node are necessarily satisfied as soon as it has received its input tokens, and it may begin executing. The execution of the nodes is thus asynchronous.~\cite{lee2015introduction}

To allow asynchronous execution of the nodes, the tokens are buffered between the nodes. A common requirement of MoCs used in signal or stream processing is the capability of executing for an undetermined amount of time. Execution without determinate end is called unbounded execution and it means that the length of the input may be arbitrarily large. The token buffering combined with the required capability for unbounded execution leads to a possibility of unbounded buffer growth. Unbounded buffer growth is one of the main problems the different dataflow MoCs try to solve. The other main problem is the schedulability of the dataflow graph. If the graph has cycles, the model may deadlock when one of the nodes has an insufficient number of input tokens and cannot proceed execution. This keeps the nodes that come after it from receiving input and thus deadlocking the graph.~\cite{lee2015introduction}

The scheduling of dataflow graphs means determining when and where the nodes execute. The execution of the nodes is dependent on the availability of data, which places restrictions on the possible schedules. The availability of data means that the node must have the specified number of tokens in each of its input queues in order to execute. Depending on the system there may be one or more cores available for execution of the nodes. For parallel systems the nodes may execute in parallel if a parallel schedule can be found that respects the data availability constraints of the graph. In order to generate efficient schedules, the scheduler must be aware of the overhead introduced by the communication between the cores.~\cite{lee1987synchronous}

\subsection{Synchronous Dataflow}
\label{subsec:synchronous-dataflow}
\FloatBarrier
One approach to solving the schedulability and the unbounded buffer growth of the dataflow MoC is fixing the production and consumption rates of the actors. These limitations are implemented in the family of dataflow models introduced by Lee and Messerschmit called synchronous dataflow (SDF)~\cite{lee1987synchronous}.

An SDF model imposes strict limits on the kinds of dataflow graphs allowed. The dataflow graphs in SDF models are fixed at compile time. No new actors may be added in run time to SDF graphs because all arcs of the model are fixed. The flow of tokens along the arcs is fixed as well, due to the fixed production and consumption rates of the model. Graphs created adhering to these limitations are fully schedulable at compile time and they execute the same way on each iteration. This means that the boundedness of the buffers is guaranteed and the deadlocking problems are avoided. Implementing such limitations reduces the expression power of SDF models compared to more lax dataflow models such as the dynamic dataflow, which is discussed in~\ref{subsec:dynamic-dataflow}.~\cite{lee2015introduction}

\begin{figure}[h!]
    \begin{center}
        \includegraphics[width=0.40\textwidth]{images/sdf_graph.pdf}
        \caption{A SDF Graph from \cite{ade1997data}. The production rate of each connection is marked at the beginning of the arcs connecting the nodes and the consumption rates are marked respectively at the end of each arc.}
        \label{fig:sdf_graph}
    \end{center}
\end{figure}

The SDF MoC was specifically designed for digital signal processing applications. In domains such as digital signal processing the typical tasks can be presented as sequence of operations performed on an infinite stream of data, which makes them computable with SDF models. The SDF models provide good performance and guarantee deadlock-free execution and thus are a practical choice for DSP applications.~\cite{lee2015introduction}

\begin{table}
    \begin{center}
        \begin{tabular}{ c c }
            Arc & Buffer Size \\ \hline
            ab  & 5 \\ \hline
            ac  & 10 \\ \hline
            bd  & 2 \\ \hline
            cd  & 10 \\ \hline
            ce  & 12 \\ \hline
            cf  & 30 \\ \hline
            df  & 6 \\ \hline
            ef  & 8 \\ \hline
        \end{tabular}
        \caption{The minimum required buffer sizes for the arcs in the SDF figure \ref{fig:sdf_graph}. The buffer sizes are presented as the maximum number of tokens the buffer fits. The buffers store the tokens that are waiting to be processed by the node in the receiving end of each arc.}
        \label{tab:sdf_buffers}
    \end{center}
\end{table}

Figure~\ref{fig:sdf_graph} presents an example acyclic SDF graph from~\cite{ade1997data}. The graph nodes are marked with letters from a to f and the production and consumption rates are marked at the ends of the arcs. The graph can be scheduled in many different ways, which yield different performance characteristics in terms of memory requirements of the buffers, latency, and throughput. The task of scheduling and allocating buffers for SDF graphs is non-trivial. Larger buffer sizes allow for more scheduling freedom but on certain targets such as FPGAs there are severe limitations on the number of registers available for the buffer allocation. The minimum required buffer sizes that guarantee the existence of deadlock-free schedule are represented in table~\ref{tab:sdf_buffers}. The buffer sizes were found using the algorithm from~\cite{ade1997data}. For some schedules that would yield improvements in throughput or latency, larger buffer sizes may be required.

Examples of practical implementations of the SDF MoC include the parameterized and interfaced synchronous dataflow (PiSDF) used by PREESM described in~\ref{subsec:preesm-internal}, the Ptolemy project \cite{ekerjanneck2003ptolemy} and the LUSTRE programming language~\cite{halbwachs1991synchronous}.

\FloatBarrier
\subsection{Dynamic Dataflow}
\label{subsec:dynamic-dataflow}
Synchronous dataflow may be a good fit for simple signal processing tasks such as signal filtering, but it is too restricted for efficiently describing more complicated algorithms. Multiple models of computation that share the basic structure of dataflow models have been developed for more advanced needs. Dataflow models of computation, which relax the constraints on token production and consumption are grouped under the name dynamic dataflow. Dynamic dataflow does not refer to a single model of computation but a group of models that differ in terms of expression power and analyzability.~\cite{bhattacharyya2013handbook}

The dynamic dataflow models of computation do not constrain the number of tokens produced or consumed by an actor in a single firing. The actors may produce and consume different numbers of tokens on different firings. Relaxation of these constraints improves the expression power of the model but makes the analysis more difficult. In the class of dataflow models where these constraints have been lifted, the boundedness of the buffers and the deadlocks in cyclic graphs are undecidable~\cite{buck1993scheduling}. Many dynamic dataflow models introduce other kinds of restrictions to replace the constraints on production of tokens. By limiting the types of the actors and available graph patterns dynamic dataflow models with decidable buffer growth and schedules are possible \cite{bhattacharyya2013handbook, gao1992well}. Choosing which dynamic dataflow model to use is about finding the right tradeoff between analyzability and expression power for the specific application.

Dynamic dataflow is suitable for processing streams of complex data, such as compressed audio or video. A common example use case for DDF in the literature is the decoder of an MPEG video stream~\cite{bhattacharyya2013handbook}. CAL actor language supports DDF MoC and it is used by the reconfigurable video coding working group to describe the MPEG encoder and decoder~\cite{bhattacharyya2011overview}. A more recent example of using DDF in practice is the TensorFlow machine learning framework developed by Google~\cite{tensorflow2015-whitepaper}.
