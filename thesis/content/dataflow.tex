\fixme{ todo intro to dataflow models of computation }
\subsection{Dataflow Models of Computation}
\label{subsec:dataflow-moc}
Dataflow models of computation can be used to describe stream processing applications. In programs following a dataflow MoC, the computation can be described by a directed graph. The nodes of the graph are the computation kernels. The data being processed by the application is split into tokens which flow from node to node along the directed arcs. The only means of communication between the nodes are the data tokens. This means a node may begin executing as soon as it has received its input tokens. The execution of the nodes is thus asynchronous.~\cite{lee2015introduction}

To allow asynchronous execution of the nodes the tokens are buffered between the nodes. A common requirement of MoCs for stream processing is the capability of unbounded execution. Unbounded execution means that length of the input may be arbitrarily large. The token buffering combined with the common requirement of unbounded execution leads to a possibility of unbounded buffer growth. Unbounded buffer growth is one of the main problems the different dataflow MoCs try to solve. The other main problem is the schedulability of the dataflow graph. If the graph has cycles, it may be possible for the model to deadlock when some node has insufficient number of input tokens and cannot execute, keeping the nodes that come after it from receiving input and thus deadlocking the graph.~\cite{lee2015introduction}

\subsection{Synchronous Dataflow}
\label{subsec:synchronous-dataflow}
One approach of solving the schedulability and buffer growth problems of the dataflow Moc is the synchronous dataflow. Synchronous dataflow was introduced by Lee and Messerschmit in \cite{lee1987synchronous} for digital signal processing applications. The actors in synchronous dataflow programs produce and consume exactly the same number of tokens each iteration. By fixing the number of tokens produced and consumed by the actors, the boundedness of buffers is guaranteed and the deadlocking problems are avoided. The problem with limiting the production and consumption of tokens is that it greatly reduces the expression power of the model.~\cite{lee2015introduction}

In some application domains such as signal processing applications the tradeoff between the limitations of synchronous dataflow and the good performance and the guarantees of the model may still be in favor of the synchronous dataflow models.~\cite{lee2015introduction}

\begin{figure}[h!]
    \begin{center}
        \input{content/openem-flowchart.tex}
        \caption{SDF model. The number of tokens produced or consumed by a port is marked by a number next to the port.\fixme{TODO}}
        \label{fig:sdf-model}
    \end{center}
\end{figure}

In the figure~\ref{fig:sdf-model} an example of a synchronous dataflow model is given. The given example model is consistent with the SDF MoC and thus a schedule that can be repeated forever can be found.

A practical example of a synchronous dataflow MoC is the parameterized and interfaced synchronous dataflow (PiSDF) MoC used by PREESM. PiSDF is described in in~\ref{subsec:preesm-internal}.

\subsection{Dynamic Dataflow}
\label{subsec:dynamic-dataflow}
Synchronous dataflow may be a good fit for simple signal processing tasks such as signal filtering, but it is too restricted for efficiently describing more complicated algorithms. Multiple models of computation that share the basic structure of dataflow models have been developed for more advanced needs. Dataflow models of computation that relax the constraints on token production and consumption are grouped under the name dynamic dataflow. Dynamic dataflow does not refer to a single model of computation but a group of models that differ in terms of expression power and analysability.~\cite{bhattacharyya2013handbook}

The dynamic dataflow models of computation do not constrain the number of tokens consumed or produced by an actor in a single firing. The actors may produce and consume different numbers of tokens on different firings. Relaxation of these constraints improves the expression power of the model but makes the analysis more difficult. In the class of dataflow models where these constraints have been lifted the boundedness of the buffers and the deadlocks of the cyclic graphs are undecidable \cite{buck1993scheduling}. Many dynamic dataflow models introduce other kinds of restrictions to replace the constraints on production of tokens. By limiting the types of the actors and available graph patterns dynamic dataflow models with decidable buffer growth and schedules are possible \cite{bhattacharyya2013handbook, gao1992well}. Choosing which dynamic dataflow model to use is about finding the right tradeoff between analysability and expression power for the specific application.

Dynamic dataflow is suitable for processing streams of complex data, such as compressed audio or video. A common example use case for DDF in the literature is the decoder of MPEG video stream~\cite{bhattacharyya2013handbook}. CAL actor language supports DDF MoC and it is used by the reconfigurable video coding working group to describe the MPEG encoder and decoder~\cite{bhattacharyya2011overview}. A more recent example of using DDF in practice is in the TensorFlow machine learning framework developed by Google~\cite{tensorflow2015-whitepaper}.
