The single-thread performance of computer hardware grew rapidly, even exponentially, for many decades. This growth was reflected in software development where many software developers mainly focused on developing single-threaded programs. The main driver of single threaded performance was the increasing clock-speed of the CPUs. These increases in clock-speed slowed down around 2005 and hardware manufacturers turned more of their focus toward multicores. While parallel computing has been researched and practiced for decades, its importance has grown greatly after the proliferation of multicore processors.~\cite{sutter2005free}

In Open Event Machine work is done in entities known as execution objects. Multiple cores can execute instances of the same execution object or different execution objects depending on the application and the scheduler. The execution objects communicate with each other using events. The events are enqueued in queues and dequeued by the scheduler according to its scheduling rules. In OpenEM an execution object is scheduled for execution when the scheduler dequeues an event from a queue attached to the execution object. The OpenEM model of parallelism is described in detail in the following sections. In this section a closer look is taken into task parallelims~\ref{subsec:task-parallelism}, which is the form of parallelism implemented by the OpenEM framework and event-driven programming~\ref{subsec:event-driven-programming}, which is a model of concurrency closely related to OpenEM.

\subsection{Task Parallelism}
\label{subsec:task-parallelism}
Task parallelism is a form of parallelism, in which units of work are distributed among multiple cores. The units of work in task parallelism are called tasks. The unit of work consists of code and data in contrast to data parallelism where the same task is performed on multiple pieces of data.~\cite{hennessy2011computer} Task parallelism can be flexibly used to construct parallel programs, as the different tasks can consist of work unrelated to each other. This makes task parallelism useful with handling irregular parallelism~\cite{ayguade2009design}. The coupling results in overhead compared to data parallel models, and thus the grain size of computation needs to be sufficiently large for efficient task parallelism~\cite{subhlok1993exploiting}.

With dependencies between the tasks of the program the programmer may avoid having to manually synchronize the threads of execution. Introduction of dependencies between the tasks limits the possible orders of execution. Task parallelism does not dictate the use of dependencies and the programmer may choose to synchronize the tasks themself.~\cite{hennessy2011computer}

Examples of task parallel systems include the Grand Central Dispatch by Apple~\cite{sakamoto2012grand}, OpenMP implements tasks from version 3.0 onwards~\cite{ayguade2009design} and Intel Thread Building Blocks~\cite{pheatt2008intel}.

\subsection{Event-driven Programming}
\label{subsec:event-driven-programming}
Concurrency is more and more common in modern computing. There are multiple reasons why concurrency is so important. Probably the biggest reason for increased concurrency in software is that the single-threaded performance of the hardware is not growing as rapidly as it was in the past~\cite{sutter2005free}. Apart from increasing the amount of computation done in parallel, other reasons for increasing concurrency in programs are handling asynchronous IO and responding to external events such as user interactions.

IO operations often take long compared to computation on the CPUs. In IO heavy applications multiple IO operations can be started concurrently and their results be processed in the order of completion. Such concurrent waiting increases the CPU utilization as the CPUs are not spending time busy waiting for IO but instead processing the results of completed IO operations.~\cite{dabek2002event}

Commonly IO operations consist of three phases. In the first phase the operation is set up, the target hardware could be for example the hard drive of the device. In the second phase the CPU waits for the operation to complete and has nothing to do with regards to the particular operation. In the third phase the CPU is notified of the availability of results and begins processing them. Only phases one and three require active processing from the CPU.~\cite{friesen2015asynchronous}

A common way of enabling concurrency in programs is to split the execution of the program across multiple software threads. Using threads for concurrent programming is convenient because they allow interleaving IO and computation while preserving the appearance of a serial program. A separate thread could be spawned for each IO operation so that a non-blocked thread can execute while the IO thread is waiting. The use of threads has disadvantages. For example, they introduce concurrency even to sections of programs where it is not needed. Programming with threads requires explicit synchronization of the threads, which in practice yields data races and deadlocks. Spawning software threads consumes processing cycles and memory, making full software threads often heavier than necessary for the task in hand.~\cite{dabek2002event, lee2006problem}

Concurrent processing of IO and UI generated events does not necessitate the spawning of a thread for each operation. Another way of handling concurrent events is by registering an event handler with a central system that keeps track of completed operations. Such central system is commonly called the event loop. The event loop checks completion of operations and calls the registered event handlers when the results are available. For example the Node.js~\cite{tilkov2010node} and Apple's Grand Central Dispatch~\cite{sakamoto2012grand} frameworks make use of such model of concurrency. The event-driven concurrent programming model leaves the mapping of event loops and details of how events are dispatched to its implementations. One or more threads can execute event loops and the events can even be dispatched from one thread on another depending on the implementation.

Dabek et al. argue for the use of events instead of threads to provide concurrency in IO heavy server environments. The benefits of events are that they provide comparable concurrency as threads in concurrent IO programs but are easier to program and tend to yield more stable performance under heavy loads.~\cite{dabek2002event} This along with the other advantages of events in concurrent programming have generated enough interest that many event-driven processing concepts have been developed. Here are some examples. Event-driven runtime with its own programming language called Eve has been developed by Fonseca et al.~\cite{fonseca2014eve}. Node.js implements event-driven processing. Majority of the UI libraries such as QT~\cite{blanchette2006cpp} are implemented in an event-driven pattern.
